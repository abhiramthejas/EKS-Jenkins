---
- name: "AWS inventory create"
  hosts: localhost
  tasks:

    - name: "Collect build ec2 instance"
      amazon.aws.ec2_instance_info:
        region: ap-south-1
        filters: 
          "tag:Name": jenkins
          instance-state-name: [ "running"]
      register: ec2_build


    - name: "build inventory"
      debug:
       msg: "instance ID : {{item.public_ip_address}}"
      with_items: "{{ec2_build.instances}}" 


    - name: "Add build hosts to inventory"
      add_host:
        name: "{{item.public_ip_address}}"
        ansible_ssh_host: "{{item.public_ip_address}}"
        ansible_ssh_port: 22
        groups: 
          - infra_instances
        ansible_ssh_common_args: "-o StrictHostKeyChecking=no"
      with_items: "{{ec2_build.instances}}"



- name: Checking infra clone
  hosts: infra_instances
  become: true
  vars_files:
    - vars.yml
  tasks:

    - name: "Git clone"
      git:
        repo: "{{ terraform_repo }}"
        dest: "{{terraform_dir}}"
      register: clone_status

    - name: "Infra build using Terraform"
      when: clone_status.changed == true
      community.general.terraform:
        project_path: "{{terraform_dir}}"
        state: present
        force_init: true


- name: "Initilize kubectl"
  hosts: infra_instances
  vars_files:
    - vars.yml
  tasks:
  
    - name: "Add EKS to instance"
      when: clone_status.changed == true
      raw: aws eks update-kubeconfig --region "{{ lookup('env','region_code') }}" --name "{{ lookup('env','cluster_name') }}"

    - name: "Check kubectl"
      when: clone_status.changed == true
      raw: kubectl get svc

    - name: "Autoscaler add"
      when: clone_status.changed == true
      shell:
        chdir: "{{workspace_dir}}"
        cmd: kubectl apply -f cluster-autoscaler.yml
    



    
